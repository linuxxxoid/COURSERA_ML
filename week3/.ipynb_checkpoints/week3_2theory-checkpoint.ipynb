{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Что делать если модель переобучилась?\n",
    "\n",
    "- уменьшить мощность модели, взять более простую модель\n",
    "\n",
    "Например, в случае линейной регрессии, мы можем попытаться уменьшить мощность нашей модели, например, построить полином в меньшей степени, в таком случае наша модель будет более простой и будет пытаться описывать действительную реальную природную зависимость данных, а не какие-то шумовые выбросы.\n",
    "\n",
    "- регуляризация\n",
    "\n",
    "С помощью регуляризации мы можем попытаться найти модель, которая будет описывать данные лучше. Регуляризация как раз пытается сделать так, чтобы мы нашли максимально простую модель, модель, например, с наименьшими весами в случае линейной регрессии. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассмотрим регуляризацию L2:\n",
    "\n",
    "$ridge\\_loss = \\frac {-1}{N} \\sum\\limits_{i = 0}^{N} (y_i - \\hat{y_i})^2 + \\lambda \\sum\\limits_{i = 1}^{k} w_i^2$\n",
    "\n",
    "N - размер выборки\n",
    "\n",
    "$y_i$ - корректный ответ\n",
    "\n",
    "$\\hat{y_i}$ - предсказанный ответ\n",
    "\n",
    "$\\lambda$ - вес при регуляризаторе\n",
    "\n",
    "$w_i$ - веса модели\n",
    "\n",
    "k - количество весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 добавляет еще одно слагаемое в наш Loss, в нашу функцию потерь, которое пытается сделать так, чтобы наши веса были поменьше.\n",
    "\n",
    "А мы добавляем лямбду и сумму квадратов наших весов. \n",
    "\n",
    "Таким образом, мы штрафуем дополнительно за большие веса. Большие веса соответствуют каким-то большим пикам в нашей линейной регрессии.Мы пытаемся сделать так, чтобы их не было.\n",
    "\n",
    "Таким образом мы пытаемся найти функцию в семействе всех функций, которые нам могут подойти, которая будет попроще, которая будет хорошо описывать природную зависимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим регуляризацию L1:\n",
    "\n",
    "$lasso\\_loss = \\frac {-1}{N} \\sum\\limits_{i = 0}^{N} (y_i - \\hat{y_i})^2 + \\lambda \\sum\\limits_{i = 1}^{k} |w_i|$\n",
    "\n",
    "N - размер выборки\n",
    "\n",
    "$y_i$ - корректный ответ\n",
    "\n",
    "$\\hat{y_i}$ - предсказанный ответ\n",
    "\n",
    "$\\lambda$ - вес при регуляризаторе\n",
    "\n",
    "$w_i$ - веса модели\n",
    "\n",
    "k - количество весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### L1 регуляризация\n",
    "\n",
    "которая использует модули весов. Она, позволяет отбирать наши признаки таким образом, чтобы мы зануляли признаки, которые не нужны для нашей модели. \n",
    "\n",
    "Итак, регуляризация помогает вам бороться с оверфиттингом, бороться с переобучением позволяя выделить какую-то конкретную функцию в семействе всех функций, которая нам подходит, сделать так чтобы она была простой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы побороть переобучение данные делят на 3 части.\n",
    "\n",
    "- тренировочная - обучаем модель\n",
    "\n",
    "- тестовая - подбираем параметры\n",
    "\n",
    "- валидационная - фиксируем итоговое качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross validation\n",
    "Еще одним очень популярным методом валидации, методом разбиения является кросс-валидация.\n",
    "\n",
    "- разбиваем датасет на К равных частей\n",
    "\n",
    "- по очереди используем одну из частей как тестовую, а остальные К - 1 в качестве тренировочной, потом меняем\n",
    "\n",
    "- усредняем качество по всем К разбиениям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Смещение и разброс\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beyons warian trade-off или trade-off между смещением и разбросом. \n",
    "\n",
    "С одной стороны, если мы построим модель, которая слишком хорошо описывает тренировочную выборку, у нас будет большой variance, когда мы попытаемся использовать нашу модель на других данных у нас будет большой разброс в оценках.\n",
    "\n",
    "С другой стороны, если мы построим слишком простую модель, которая слабо описывает тренировочную выборку, то есть андерфитится - не дописывает ее, то у нас просто будет плохое предсказание с каким-то смещением. Таким образом мы пытаемся играть в эту игру и это называется beyons warian trade-off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики качества\n",
    "\n",
    "### Классификация\n",
    "\n",
    "В случае классификации вы предсказываете 0 либо 1.\n",
    "\n",
    "- матрица ошибок.\n",
    "\n",
    "Если у вас модель сработала и показала 1, а на самом деле должен быть 0, то это false positive, а если вы показали 0 там, где должен быть 0, это true negative. \n",
    "\n",
    "- accuracy\n",
    "\n",
    "$accuracy = \\frac {TP + TN}{TP + FP + TN + FN}$\n",
    "\n",
    "то есть доля правильных ответов в вашей модели. Сколько раз в принципе ваша модель корректно сработала, то есть все true positive и true negative нормированы на полное количество ответов. \n",
    "\n",
    "Если есть дисбаланс классов, то использование ее неприменимо.\n",
    "\n",
    "- точность\n",
    "\n",
    "$precision = \\frac {TP}{TP + FP}$\n",
    "\n",
    "Precision показывает долю корректного срабатывания среди всех положительных срабатываний, то есть, если мы показываем 1 насколько часто мы делаем это точно. \n",
    "\n",
    "- полнота\n",
    "\n",
    "$recall = \\frac {TP}{TP + FN}$\n",
    "\n",
    "\n",
    "Recall говорит о том, насколько много 1 в целом мы нашли, как полно мы описали наши данные. Их можно использовать в случае дисбаланса классов и часто именно так и делается.\n",
    "\n",
    "- F1-мера\n",
    "\n",
    "$F1 = \\frac {2 * precision * recall}{precision + recall}$\n",
    "\n",
    "\n",
    "F-мера гармоническое среднее между precision и recall.\n",
    "\n",
    "- logloss\n",
    "\n",
    "$logloss = \\frac {-1}{N} \\sum\\limits_{i = 0}^{N} y_i *  \\log{(\\hat{y_i})} + (1 - y_i) * \\log{(1 - \\hat{y_i})}$\n",
    "\n",
    "\n",
    "$N$ - размер выборки\n",
    "\n",
    "$y_i$ - корректный ответ\n",
    "\n",
    "$\\hat{y_i}$ - предсказанный ответ \n",
    "\n",
    "Также существует logloss, которую можно рассматривать как какое-то взвешенное accuracy, то есть наш logloss сильно штрафуют за уверенность в неправильном ответе.\n",
    "\n",
    "\n",
    "- ROC AUC\n",
    "\n",
    "$true\\_positive\\_rate = \\frac {TP}{TP + FN}$\n",
    "\n",
    "$false\\_positive\\_rate = \\frac {FP}{FP + TN}$\n",
    "\n",
    "\n",
    "Мы откладывает true positive rate против false positive rate. у нас высчитывается площадь под нашей построенной кривой, таким образом, если наша площадь равна 1, если мы полностью закрыли единичный квадрат, то у нас наш классификатор является идеальным. Если у нас площадь около 0,5, то он примерно случайный и смысла большого не имеет. \n",
    "\n",
    "- PERSI AUC\n",
    "\n",
    "То же самое с precision и recall кривой, которая часто используется в случае дисбаланса классов. Здесь если у нас 1 у нас классификатор идеальный. \n",
    "\n",
    "\n",
    "### Регрессия\n",
    "\n",
    "В случае регрессии мы предсказывали какое-то действительное число. \n",
    "\n",
    "- MAE или средняя абсолютная ошибка\n",
    "\n",
    "$MAE = \\frac {1}{N} \\sum\\limits_{i = 1}^{N} |y_i -  \\hat{y_i}|$\n",
    "\n",
    "\n",
    "\n",
    "показывает на то, как далеко наши ответы в среднем стоят от корректных, то есть мы суммируем расстояние до корректных предсказаний от наших попыток описать данные \n",
    "\n",
    "- MSE\n",
    "\n",
    "$MSE = \\frac {1}{N} \\sum\\limits_{i = 1}^{N} (y_i -  \\hat{y_i})^2$\n",
    "\n",
    "MSE делает то же самое с квадратным расстоянием и усредняет по всем объектам.\n",
    "\n",
    "- RMSE\n",
    "\n",
    "$RMSE = \\sqrt{MSE}$\n",
    "\n",
    "Так же мы можем взять корень из MAE и получить RMSE метрику, которая часто используется. \n",
    "\n",
    "- R-squared или коэффициент детерминации.\n",
    "\n",
    "$R^2 = 1 - \\frac {\\sum\\limits_{i = 1}^{N} (y_i -  \\hat{y_i})^2}{\\sum\\limits_{i = 1}^{N} (y_i -  \\hat{y})^2}$\n",
    "\n",
    "$N$ - размер выборки\n",
    "\n",
    "$y_i$ - корректный ответ\n",
    "\n",
    "$\\hat{y_i}$ - предсказанный ответ \n",
    "\n",
    "$\\hat{y}$ - среднее значение по выборке\n",
    "\n",
    "Коэффициент детерминации показывает, как хорошо мы можем описать дисперсию в наших данных. Что важно тут знать, коэффициент детерминации может лежать от минус бесконечности до единицы. В случае единицы у нас, мы показываем идеальное качество, а если у нас R-squared меньше нуля, то смысла наша модель большого не имеет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
