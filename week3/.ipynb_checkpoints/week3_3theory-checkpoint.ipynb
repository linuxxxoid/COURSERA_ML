{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже знакомы с методами линейной классификации, линейной регрессии, в целом с линейными моделями, однако их можно использовать, как следует из их названия, только в случае каких-то линейных зависимостей.\n",
    "\n",
    "## Решающие деревья\n",
    "\n",
    " по каким-то критериям, по каким-то вопросам постепенно сойтись к листу. В случае классификации у нас в листе будет класс, в случае регрессии, например, какой-то диапазон. Можно представить себе решающие деревья как алгоритм, который последовательно разбивает пространство по каким-то различным критериям.\n",
    " \n",
    "#### Построение решающего дерева\n",
    "\n",
    "- последовательно разбиваем объекты по критерию\n",
    "\n",
    "- максимизируем количество \"похожих\" объеектов в поддереве, нормируя по количеству объектов\n",
    "\n",
    "- строим до какой-то глубины или степени дискретизации ответа\n",
    "\n",
    "- в листе берем среднее значение (в случае регрессии) или самый частый класс (Классификация)\n",
    "\n",
    "Деревья сами по себе почти никогда не используются, только в композиции (ансамбле). Тк деревья легко переобучаются. Если построить глубокое дерево, то смысла в нем большого не будет, оно будет переобучено на тренировочную выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный лес (Random Forest)\n",
    "\n",
    "Это композиция большого количества различных решающих деревьев. Они строятся на подмножествах признаков, на подмножествах объектов и не переобучаются. Также они позволяют обучать себя параллельно, что часто используется для увеличения их производительности.\n",
    "\n",
    "### Композиция базовых алгоритмов\n",
    "\n",
    "- слабые разные базовые алгоритмы (используем их все вместе, как-то усредняем)\n",
    "\n",
    "- у алгоритмов большой разброс, они переобучены (по отдельности использовать их нет смысла, но вместе - сила)\n",
    "\n",
    "#### Построение случайного леса\n",
    "\n",
    "При построении случайного леса мы независимо строим большое количество различных решающих деревьев. Как же сделать их различными? Можем брать какие-то подмножества объектов или признаков. Объекты, например, мы можем брать с помощью алгоритма, который называется bootstrap.\n",
    "\n",
    "- для построения дерева используются случайные подмножества объектов или признаков\n",
    "\n",
    "- Bootstrap, out-of-bag (валидация)\n",
    "\n",
    "тренировочная выборка размера m, мы можем взять оттуда n объектов с возвращением. Таким образом мы каждый раз берем объект и оставляем его там же, и можем, в принципе, взять его второй раз. Таким образом у нас в нашу тренировочную выборку, которая на самом деле используется, попадают 63% примерно объектов, и мы на них обучаемся. Остальные, например, мы можем использовать для валидации, это называется out-of-bag.\n",
    "\n",
    "- деревья строят независимо\n",
    "\n",
    "- при разбиении в вершине можно брать случайное подмножество признаков\n",
    "\n",
    "- ансамбли редко переобучаются\n",
    "\n",
    " Таким образом мы можем строить все больше и больше различных решающих деревьев, их усреднять, и у нас будет все лучше и лучше качество расти.\n",
    " \n",
    "Однако есть и минусы. Например, нам нужно строить действительно глубокие деревья, чтобы они получались переобученными, и чтобы у них был большой разброс, они строятся долго - это трудозатратно. Дает хорошее качество, но обучать достаточно сложно.\n",
    "\n",
    "Построение решающих деревьев в случайном лесе происходит независимо\n",
    "\n",
    "Число решающих деревьев в случайном лесе влияет на качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг\n",
    "\n",
    "это тоже ансамблиевая модель\n",
    "\n",
    "Популярный метод машинного обучения с учителем, как градиентный бустинг над решающими деревьями. \n",
    "\n",
    "- базовые алгоритмы строятся зависимо\n",
    "\n",
    "- каждый следующий пытается исправить ошибки предыдущего\n",
    "\n",
    "(делаем до тех пор, пока итоговое качество не будет нас устраивать)\n",
    "\n",
    "- достаточно небольших коротких деревьев\n",
    "\n",
    "необязательно строить решающие деревья глубоко в отличие от случ леса, достаточно небольших коротких деревьев, которые постепенно добавляются к нашему базовому алгоритму. Например, они добавляются с шагом, чтобы модель не переобучалась.\n",
    "\n",
    "- гб действительно переобучается"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
