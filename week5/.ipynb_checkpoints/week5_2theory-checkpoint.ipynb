{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверточный слой\n",
    "\n",
    "\n",
    "Сверточная нейронная сеть — это обычная нейронная сеть с новыми типами слоев. Эти слои сверточные и pooling слои. \n",
    "\n",
    "Сверточный слой представляет собой какой-то набор фильтров. Также они называются features или kernel — ядра. Итак, у нас есть какое-то количество этих самых фильтров, и они как раз непосредственно и применяются к нашему изображению с помощью операции свертки. \n",
    "\n",
    "Наш фильтр — это матрица с числами. эта матрица является параметром нашего сверточного слоя, она будет настраиваться и обучаться в процессе оптимизации нейронной сети.\n",
    "\n",
    "фильтр применяется к изобр последовательно прикладывается и считает скалярное произведение двух матриц (фильтра и выделенно области фильтром в матрице изображения), получаем матрицу активации.\n",
    "\n",
    "Таким образом, наш фильтр смотрит на то, есть ли в каком-то определенном месте на изображении какой-то определенный объект. И при обучении нейронной сети наши фильтры постепенно, постепенно выучивают определенные формы, текстуры, фигуры или более сложные объекты. Важно понимать, что даже обычное изображение обычно состоит не только из матрицы и пикселей, но и также у него есть какая-то глубина, например, количество каналов может быть три — RGB. Таким образом, наши фильтры могут быть не просто матрицей, а, например, тензором и так далее.\n",
    "\n",
    "\n",
    "### pooling слой\n",
    "\n",
    "Второй слой, который часто используется в сверточных нейронных сетях, более простой — это pooling слой, или слой субдискретизации, который по сути дела downsampling, то есть уменьшение размера изображения.\n",
    "\n",
    "1 2 2 4\n",
    "\n",
    "5 6 7 8\n",
    "\n",
    "3 2 1 0\n",
    "\n",
    "1 2 3 4\n",
    "\n",
    "max pool with 2x2 filters and stride = 2 \n",
    "=> \n",
    "\n",
    "6 8\n",
    "  \n",
    "3 4\n",
    "\n",
    "Например, max pooling просто может уменьшить в два раза наше изображение, находя в каждом квадрате, в каждой матрице какое-то максимальное значение, максимальное число пикселя и оставляя именно его. Таким образом, мы просто уменьшаем качество изображения. Это очень полезно для того, чтобы уменьшать количество параметров нашей модели.\n",
    "\n",
    "Однако в последнее время очень часто эти самые pooling слои заменяются разными трюками, например, можно делать вместо pooling слоя просто какую-то свертку с более большим шагом или можно, например, делать свертки даже один на один. \n",
    "\n",
    "Итак, важно знать, что сверточные сети — это по сути обычные сети просто с новыми типами слоев. Сверточные слои выучивают фильтры, которые распознают различные объекты наших изображений. Также очень часто в конце сверточной нейронной сети добавляются fully connected слои, то есть обычная нейронная сеть, таким образом, чтобы потом, например, решить задачу классификации.\n",
    "\n",
    "\n",
    "В сверточных нейронных сетях учитывается локальность признаков\n",
    "\n",
    "Сверточный слой содержит значительно меньше весов для настройки в сравнении с аналогичным слоем полносвязной нейронной сети\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекуррентные нейронные сети\n",
    "\n",
    "Рекуррентные нейронные сети позволяют вам хранить контекст, хранить информацию с предыдущих шагов. \n",
    "\n",
    "Например, анализируем текст. На вход может подать какое-то слово, мы выдаем предсказание и запоминаем инфу про это слово. Эта инфа (state) передается дальше, когда мы делаем слудющее предсказание. След предсказание мы делаем уже, учитывая инфу о предыдущем. На вход поступает не только след слово, но и инфа с предыд шага и тд\n",
    "\n",
    "Обучаются с помощью backpropagation с помощью модификации backpropogation through time, которая разворачивает все эти шаги.\n",
    "\n",
    " Есть несколько важных модификаций к рекуррентным нейронным сетям, одна из которых называется LSTM, или Long Short-Term Memory.\n",
    " \n",
    " LSTM – это разновидность архитектуры рекурентных нейронных сетей, способная хранить и использовать в процессе обучения долгосрочную информацию\n",
    " \n",
    " Есть также модификации GRU. Они добавляют новые блоки в нашу рекуррентную нейронную сеть, чтобы она лучше запоминала разные состояния.\n",
    " \n",
    " Как вы можете догадаться, если мы читаем какой-то длинный текст с помощью нашей рекуррентной нейронной сети, постепенно мы, так как передаем информацию с предыдущих шагов, мы так или иначе забудем информацию о том, что было достаточно далеко. И рекуррентная нейронная сети действительно страдает от такой проблемы — очень сложно помнить что-то, что было больше, например, 30 шагов назад в каком-то небольшом векторе состояния. На помощь могут прийти как раз LSTM-блоки, которые немного усложняют наше состояние — это уже не просто вектор, это уже чуть более сложный аппарат. Есть определенные gates, которые отвечают за то, что стоит ли забывать какие-то данные, которые приходят на вход, стоит ли их помнить, с каким весом их учесть и тд. Таким образом, LSTM блоки тоже обучаются. Мы настраиваемся запоминать определнные вещи в тексте.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
