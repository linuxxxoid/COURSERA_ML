{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist представляет собой набор рукописных цифр, которые мы и будем классифицировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-0ed8ae25e744>:1: read_data_sets (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From /Users/linuxoid/Desktop/COURSERA_ML/week5/input_data.py:284: _maybe_download (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/linuxoid/Desktop/COURSERA_ML/week5/input_data.py:286: _extract_images (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/linuxoid/Desktop/COURSERA_ML/week5/input_data.py:291: _extract_labels (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/linuxoid/Desktop/COURSERA_ML/week5/input_data.py:104: _dense_to_one_hot (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/linuxoid/Desktop/COURSERA_ML/week5/input_data.py:315: _DataSet.__init__ (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST/', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input_data._Datasets"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fceb4441898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = mnist.train.images[7].reshape([28, 28])\n",
    "\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[7].shape)\n",
    "print(mnist.train.labels[7].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.37254903 0.8862746  0.9921569  0.9921569\n",
      " 0.8862746  0.         0.         0.36078432 0.0509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01960784 0.29803923\n",
      " 0.97647065 0.9921569  0.9921569  0.9921569  0.8862746  0.\n",
      " 0.41176474 0.9843138  0.854902   0.34117648 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[7][150:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "num_input = 784 # 28x28\n",
    "num_classes = 10\n",
    "\n",
    "X = tf.compat.v1.placeholder('float', [None, num_input])\n",
    "Y = tf.compat.v1.placeholder('float', [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.compat.v1.Variable(tf.compat.v1.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'output': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden_1])),\n",
    "    'b2': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden_2])),\n",
    "    'output': tf.compat.v1.Variable(tf.compat.v1.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    output_layer = tf.matmul(layer_2, weights['output']) + biases['output']\n",
    "\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "определим нашу функцию потерь. Мы будем здесь минимизировать кросс-энтропию, потому что мы будем решать задачу логистической регрессии. То есть мы будем пытаться сделать так, чтобы наше распределение над классами, о котором мы предсказали, максимально соответствовало реальному распределению, то есть нашему onehot вектору.\n",
    "\n",
    "Мы передаем лейблы, передаем лоджиты, то есть полученные распределение над классами в нашу функцию, которая вычисляет кросс-энтропию и пытаемся ее минимизировать. Все это тоже оператор в нашем вычислительном графе. И поэтому они будут выпускаться позже, когда мы будем запускать нашу сессию. \n",
    "\n",
    "В качестве оптимайзера, то есть в качестве оптимизационного алгоритма мы будем использовать Adam. \n",
    "\n",
    "Зададим learn_create, который мы указали выше и будем минимизировать с помощью нашего оптимизационного алгоритма функцию потерь, которую мы задали. \n",
    "\n",
    "А дальше, мы будем минимизировать какую-то метрику. В данном случае мы будем минимизировать метрику accuracy.\n",
    "\n",
    "Приведем наши предсказания к меткам, которые у нас должны быть и будем считать accuracy в таком виде.\n",
    "\n",
    "Equal просто считать сколько у нас попало значения.\n",
    "\n",
    "Argmax находит тот самый лоджит, который у нас максимален. То есть какой класс наша нейронная сеть передает на выход. Допустим, если наш лоджит один из лоджитов будет 0,8, значит мы с уверенностью 0,8 говорим, что это, например, - 2. Именно его и найдет функция argmax, ну и мы будем считать, что это именно это предсказание. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = network(X)\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits = logits, labels = Y\n",
    "    )\n",
    ")\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае у нас train переменная отвечает за оптимизационную функцию. Вот наш оптимайзер, он минимизирует функцию потерь, которая задана и для того, чтобы наша функция оптимизации работала, для того чтобы наш граф запустить, нам нужно передать конечное значение X и Y, наши параметры feed_dict.\n",
    "\n",
    "Именно это мы и сделаем передадим batch_x и batch_y и раз в 50 эпох будем выводить отладочную информацию, будем смотреть как у нас выглядит наши accuracy.\n",
    "\n",
    "Для того, чтобы получить какую-нибудь информацию из нашего графа, мы должны запустить sess_run, то есть запустить нашу сессию и указать ту самую ноду, вершину, которую мы хотим вычислить (accuracy) и передать соответствующие параметры.\n",
    "\n",
    "Здесь мы будем смотреть accuracy на всем trainset, то есть смотреть как хорошо мы умеем предсказывать на текущем trainset и выведем эту информацию. В конце мы посчитаем итоговую accuracy, уже на тестовом сайте. То есть mnist dataset наш разбит на тренировочную и тестовую выборку. Мы обучаемся на тренировочной и в конце посмотрим нашу accuracy на тестовых объектах. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0: train accuracy = 0.3084181845188141\n",
      "Epoch #50: train accuracy = 0.8487454652786255\n",
      "Epoch #100: train accuracy = 0.8475090861320496\n",
      "Epoch #150: train accuracy = 0.852363646030426\n",
      "Epoch #200: train accuracy = 0.8599636554718018\n",
      "Epoch #250: train accuracy = 0.8708545565605164\n",
      "Epoch #300: train accuracy = 0.8378000259399414\n",
      "Epoch #350: train accuracy = 0.8520908951759338\n",
      "Epoch #400: train accuracy = 0.845727264881134\n",
      "Epoch #450: train accuracy = 0.8671818375587463\n",
      "Epoch #500: train accuracy = 0.8413272500038147\n",
      "Epoch #550: train accuracy = 0.8442545533180237\n",
      "Epoch #600: train accuracy = 0.8367817997932434\n",
      "Epoch #650: train accuracy = 0.823199987411499\n",
      "Epoch #700: train accuracy = 0.8470545411109924\n",
      "Epoch #750: train accuracy = 0.8570727109909058\n",
      "Epoch #800: train accuracy = 0.8208363652229309\n",
      "Epoch #850: train accuracy = 0.8144181966781616\n",
      "Epoch #900: train accuracy = 0.850418210029602\n",
      "Epoch #950: train accuracy = 0.8512545228004456\n",
      "Test accuracy = 0.8489999771118164\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train, feed_dict = {X: batch_x, Y: batch_y})\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            train_accuracy = sess.run(\n",
    "                accuracy, \n",
    "                feed_dict = {\n",
    "                    X: mnist.train.images,\n",
    "                    Y: mnist.train.labels\n",
    "                }\n",
    "            )\n",
    "            print('Epoch #{}: train accuracy = {}'.format(epoch, train_accuracy))\n",
    "        \n",
    "        \n",
    "    print('Test accuracy = {}'.format(\n",
    "        sess.run(\n",
    "            accuracy, \n",
    "            feed_dict = {\n",
    "                X: mnist.test.images,\n",
    "                Y: mnist.test.labels\n",
    "            }\n",
    "        )\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " У нас в цикле по эпохам. Мы бежим и каждый раз делаем одно и то же. Мы достаем следующий batch, то есть следующий набор объектов, отправляем их в наш вычислительный граф. Вычислительный граф у нас тренируется с помощью объекта train, объект train, соответствует оптимизатору adam_optimaizer, который минимизирует функцию потерь. Для того, чтобы нашу функцию потерь минимизировать, мы должны передать наши данные, прокинуть их сквозь наш вычислительный граф и получить какое-то значение. Чтобы посмотреть как хорошо наш вычислительный граф, наша модель работает, мы вычисляем метрику accuracy и передаем ее тоже в запуск сессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "n_hidden_1 = 512\n",
    "n_hidden_2 = 512\n",
    "num_input = 784 # 28x28\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dropout случайным образом во время тренировки выкидывает определенные нейроны, чтобы наши нейроны были меньше скоррелированы друг с другом и наша модель выучила более корректные природные зависимости. \n",
    " \n",
    " функция активации softmax, потому что нам нужно распределение над нашими классами, мы решаем задачу логистической регрессии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Convolution2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one.add(Dense(n_hidden_1, input_shape = (num_input,), activation = 'relu'))\n",
    "model_one.add(Dropout(0.2))\n",
    "model_one.add(Dense(n_hidden_2, activation = 'relu'))\n",
    "model_one.add(Dropout(0.2))\n",
    "model_one.add(Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2472 - accuracy: 0.9251 - val_loss: 0.0979 - val_accuracy: 0.9687\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1000 - accuracy: 0.9691 - val_loss: 0.0808 - val_accuracy: 0.9742\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0730 - accuracy: 0.9769 - val_loss: 0.0670 - val_accuracy: 0.9803\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.0675 - val_accuracy: 0.9788\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0450 - accuracy: 0.9858 - val_loss: 0.0668 - val_accuracy: 0.9787\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0412 - accuracy: 0.9866 - val_loss: 0.0691 - val_accuracy: 0.9792\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 0.0608 - val_accuracy: 0.9819\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0308 - accuracy: 0.9898 - val_loss: 0.0604 - val_accuracy: 0.9823\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.9833\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0698 - val_accuracy: 0.9801\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0635 - val_accuracy: 0.9824\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.0675 - val_accuracy: 0.9839\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.0695 - val_accuracy: 0.9842\n",
      "Epoch 14/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.0729 - val_accuracy: 0.9833\n",
      "Epoch 15/1000\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0741 - val_accuracy: 0.9817\n",
      "Epoch 16/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0755 - val_accuracy: 0.9826\n",
      "Epoch 17/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.0785 - val_accuracy: 0.9838\n",
      "Epoch 18/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0767 - val_accuracy: 0.9831\n",
      "Epoch 19/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0747 - val_accuracy: 0.9836\n",
      "Epoch 20/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0738 - val_accuracy: 0.9828\n",
      "Epoch 21/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.0888 - val_accuracy: 0.9817\n",
      "Epoch 22/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0807 - val_accuracy: 0.9825\n",
      "Epoch 23/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.0905 - val_accuracy: 0.9827\n",
      "Epoch 24/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0798 - val_accuracy: 0.9842\n",
      "Epoch 25/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0844 - val_accuracy: 0.9850\n",
      "Epoch 26/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0871 - val_accuracy: 0.9845\n",
      "Epoch 27/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0848 - val_accuracy: 0.9839\n",
      "Epoch 28/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0868 - val_accuracy: 0.9848\n",
      "Epoch 29/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0800 - val_accuracy: 0.9838\n",
      "Epoch 30/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0990 - val_accuracy: 0.9838\n",
      "Epoch 31/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0833 - val_accuracy: 0.9837\n",
      "Epoch 32/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0955 - val_accuracy: 0.9842\n",
      "Epoch 33/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0849 - val_accuracy: 0.9848\n",
      "Epoch 34/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1029 - val_accuracy: 0.9834\n",
      "Epoch 35/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0929 - val_accuracy: 0.9831\n",
      "Epoch 36/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.1080 - val_accuracy: 0.9826\n",
      "Epoch 37/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.0918 - val_accuracy: 0.9842\n",
      "Epoch 38/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.1024 - val_accuracy: 0.9830\n",
      "Epoch 39/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0990 - val_accuracy: 0.9852\n",
      "Epoch 40/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0918 - val_accuracy: 0.9841\n",
      "Epoch 41/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1057 - val_accuracy: 0.9826\n",
      "Epoch 42/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0953 - val_accuracy: 0.9854\n",
      "Epoch 43/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0985 - val_accuracy: 0.9848\n",
      "Epoch 44/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0933 - val_accuracy: 0.9850\n",
      "Epoch 45/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1118 - val_accuracy: 0.9817\n",
      "Epoch 46/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0952 - val_accuracy: 0.9847\n",
      "Epoch 47/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.1182 - val_accuracy: 0.9832\n",
      "Epoch 48/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.1122 - val_accuracy: 0.9840\n",
      "Epoch 49/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.1000 - val_accuracy: 0.9851\n",
      "Epoch 50/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.1043 - val_accuracy: 0.9851\n",
      "Epoch 51/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1006 - val_accuracy: 0.9854\n",
      "Epoch 52/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0936 - val_accuracy: 0.9854\n",
      "Epoch 53/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.1027 - val_accuracy: 0.9841\n",
      "Epoch 54/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0969 - val_accuracy: 0.9846\n",
      "Epoch 55/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0984 - val_accuracy: 0.9852\n",
      "Epoch 56/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.0960 - val_accuracy: 0.9850\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1101 - val_accuracy: 0.9843\n",
      "Epoch 58/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.1130 - val_accuracy: 0.9850\n",
      "Epoch 59/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.0964 - val_accuracy: 0.9848\n",
      "Epoch 60/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.1092 - val_accuracy: 0.9833\n",
      "Epoch 61/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1170 - val_accuracy: 0.9833\n",
      "Epoch 62/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.1160 - val_accuracy: 0.9857\n",
      "Epoch 63/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.1125 - val_accuracy: 0.9836\n",
      "Epoch 64/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.1220 - val_accuracy: 0.9844\n",
      "Epoch 65/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.1001 - val_accuracy: 0.9859\n",
      "Epoch 66/1000\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.1107 - val_accuracy: 0.9845\n",
      "Epoch 67/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0970 - val_accuracy: 0.9857\n",
      "Epoch 68/1000\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1022 - val_accuracy: 0.9861\n",
      "Epoch 69/1000\n",
      "424/469 [==========================>...] - ETA: 0s - loss: 0.0082 - accuracy: 0.9980"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d30b71b8475c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_one.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = tensorflow.keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "nn = model_one.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    verbose = 1,\n",
    "    validation_data = (x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a model\n",
    "model = Sequential()\n",
    "\n",
    "# First conv layer\n",
    "model.add(Conv2D(64, KERNEL_SIZE, input_shape=INPUT_SHAPE,\n",
    "                 activation='relu', use_bias=True, strides=1, padding='same'))\n",
    "\n",
    "# Second conv layer\n",
    "model.add(Conv2D(64, KERNEL_SIZE, activation='relu',\n",
    "                 strides=1, use_bias=True, padding='same'))\n",
    "\n",
    "# First pool layer\n",
    "model.add(MaxPooling2D(pool_size=POOL_SIZE, strides=2))\n",
    "\n",
    "# Third conv layer\n",
    "model.add(Conv2D(128, KERNEL_SIZE, activation='relu',\n",
    "                 strides=1, use_bias=True, padding='same'))\n",
    "\n",
    "# Fourth conv layer\n",
    "model.add(Conv2D(128, KERNEL_SIZE, activation='relu',\n",
    "                 strides=1, use_bias=True, padding='same'))\n",
    "\n",
    "# Second pool layer\n",
    "model.add(MaxPooling2D(pool_size=POOL_SIZE, strides=2))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# FC layers\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=4, activation='sigmoid'))\n",
    "\n",
    "return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
