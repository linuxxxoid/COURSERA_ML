{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети. Основы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация перцептрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перцептрон - это модель, предложенная Френком Розенблаттом в 1957 году и являющаяся прообразом современных нейронных сетей. По своей сути она представляет из себя значительно упрощенную схему восприятия информации мозгом. Целью этого практического задания будет реализация собственной модели перцептрона. Давайте разберем схему работы этого алгоритма в деталях.\n",
    "\n",
    "* Мы работаем с тренировочной выборкой $S = \\{(x_i, y_i)| i \\in \\{1,...,m\\} \\}$\n",
    "* Инициализируем веса $\\omega^{(0)} \\leftarrow 0$ нулевым вектором.\n",
    "* Инициализирует bias параметр $b = 0$.\n",
    "* В начальный момент времени номер шага $t=0$.\n",
    "* Задаем learning rate $\\eta > 0$.\n",
    "* Пока значение $t < t_{\\max}$\n",
    "    * случайно выбираем объект из тренировочной выборки $(x_i, y_i) \\in S$.\n",
    "    * если выполняется условие $y_i (\\langle \\omega^{(t)}, x_i\\rangle + b) \\leq 0$ тогда\n",
    "        * $b^{(t+1)} \\leftarrow b^{(t)} + \\eta \\times y_i$.\n",
    "        * $\\omega^{(t+1)} \\leftarrow \\omega^{(t)} + \\eta \\times y_i \\times x_i$.\n",
    "    * далее, обновляем $t \\leftarrow t+1$.\n",
    "\n",
    "Таким образом, финальное значение ветора весов $\\omega$ и bias параметра $b$ позволяют классифицировать новый объект $x$. Если $(\\langle \\omega, x \\rangle + b) \\geq 0$, то мы относим объект к классу $+1$, в противном случае мы относим объект к классу $-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим датасет для задачи классификации цветков Ириса с помощь функции `load_iris` из `sklearn.datasets`. Давайте подготовим данные для задачи бинарной классификации. Для этого выберем первые 100 элементов из данного набора данных. Так же преобразуем класс $0$ в класс $-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X, y = X[:100], y[:100]\n",
    "num_features = X.shape[1]\n",
    "y = np.array([1 if y_i == 1 else -1 for y_i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9, 3. , 1.4, 0.2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.9,  1. , -0.6, -1.8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1] - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм перцептрона приведенный выше. Для выборки случайного объекта из тренировочного датасета по индексу используйте функцию `randint` из модуля `random` с параметрами 0 и n, где n - это размер тренировочно выборки. Перед запуском итераций алгоритма установите `random.seed(42)`. Вы можете реализовать перцептрон в качестве класса с интерфейсом, похожим на интерфейсы моделей из `scikit-learn`. Для этого достаточно реализовать функцию `fit` и `predict` для решения этого практического задания. Однако, ваша реализация может отличаться. Необходимое требование - это использование генератора случайных чисел, описанного выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    \n",
    "    def __init__(self, num_features, learning_rate, t_max):\n",
    "        self.__num_features = num_features\n",
    "        self.__learning_rate = learning_rate\n",
    "        self.__t_max = t_max\n",
    "        self.__bias = 0.0\n",
    "        self.__weight = np.zeros(num_features)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return self.__num_features\n",
    "    \n",
    "    @num_features.setter\n",
    "    def num_features(self, num_features):\n",
    "        if num_features > 0:\n",
    "            self.__num_features = num_features\n",
    "        else:\n",
    "            raise ValueError\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def learning_rate(self):\n",
    "        return self.__learning_rate\n",
    "    \n",
    "    @learning_rate.setter\n",
    "    def learning_rate(self, learning_rate):\n",
    "        if learning_rate > 0:\n",
    "            self.__learning_rate = learning_rate\n",
    "        else:\n",
    "            raise ValueError\n",
    "            \n",
    "            \n",
    "    @property\n",
    "    def t_max(self):\n",
    "        return self.__t_max\n",
    "    \n",
    "    @t_max.setter\n",
    "    def t_max(self, t_max):\n",
    "        if t_max > -1:\n",
    "            self.__t_max = t_max\n",
    "        else:\n",
    "            raise ValueError\n",
    "            \n",
    "    @property\n",
    "    def bias(self):\n",
    "        return self.__bias\n",
    "    \n",
    "    @bias.setter\n",
    "    def bias(self, bias):\n",
    "        if bias > -1:\n",
    "            self.__bias = bias\n",
    "        else:\n",
    "            raise ValueError\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.__weight\n",
    "    \n",
    "    @weight.setter\n",
    "    def weight(self, weight):\n",
    "        if len(weight) > 0:\n",
    "            self.__weight = weight\n",
    "        else:\n",
    "            raise ValueError\n",
    "            \n",
    "            \n",
    "    def fit(self, x, y, random_state = 42):\n",
    "        n = len(x)\n",
    "        t = 0        \n",
    "        random.seed(random_state)\n",
    "        \n",
    "        while t < self.t_max:\n",
    "            i = random.randint(0, n - 1)\n",
    "            if (y[i] * (np.dot(self.weight, x[i]) + self.bias)) <= 0:\n",
    "                self.bias += self.learning_rate * y[i]\n",
    "                self.weight += self.learning_rate * y[i] * x[i]\n",
    "            t += 1\n",
    "            \n",
    "    \n",
    "    def predict(self, x):\n",
    "        prediction_y = []\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            if (np.dot(self.weight, x[i]) + self.bias) >= 0:\n",
    "                prediction_y.append([1])\n",
    "            else:\n",
    "                prediction_y.append([-1])\n",
    "        return prediction_y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом является проверка нашей модели. Случайно разделите выборку на тренировочный и тестовый датасет, используя функцию `tran_test_split` с параметрами `test_size=0.25` и `random_state=10`. Запустите обучение модели с параметрами $\\eta=0.1$ и $t_{\\max}=40$. Оцените качество на тестовой выборке и запишите результат в переменную `score` с точность до двух знаков после запятой, используя метрику `accuracy`. Это значение и будет являться ответом на это практическое задание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "model = Perceptron(num_features, 0.1, 40)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = round(accuracy_score(y_test, y_pred), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строка с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"score {0:.2f}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
